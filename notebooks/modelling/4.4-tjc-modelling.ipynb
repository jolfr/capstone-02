{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>zipcode</th>\n",
       "      <th>start_year</th>\n",
       "      <th>avg_eqi_year_5-10</th>\n",
       "      <th>year_1_EQI_MSA</th>\n",
       "      <th>year_1_EQI_state</th>\n",
       "      <th>year_1_EQI_zip</th>\n",
       "      <th>year_1_RECPI_MSA</th>\n",
       "      <th>year_1_RECPI_state</th>\n",
       "      <th>year_1_RECPI_zip</th>\n",
       "      <th>year_2_EQI_MSA</th>\n",
       "      <th>...</th>\n",
       "      <th>recpi_state_change_2</th>\n",
       "      <th>recpi_state_change_3</th>\n",
       "      <th>recpi_state_change_4</th>\n",
       "      <th>avg_eqi_year_1-5</th>\n",
       "      <th>dataset_cluster</th>\n",
       "      <th>zip_cluster</th>\n",
       "      <th>msa_cluster</th>\n",
       "      <th>state_cluster</th>\n",
       "      <th>eqi_cluster</th>\n",
       "      <th>recpi_cluster</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1001</td>\n",
       "      <td>1992</td>\n",
       "      <td>0.001287</td>\n",
       "      <td>0.001549</td>\n",
       "      <td>0.002111</td>\n",
       "      <td>0.002216</td>\n",
       "      <td>1.176876</td>\n",
       "      <td>28.052156</td>\n",
       "      <td>0.048744</td>\n",
       "      <td>0.001266</td>\n",
       "      <td>...</td>\n",
       "      <td>1.020560</td>\n",
       "      <td>1.036390</td>\n",
       "      <td>1.251689</td>\n",
       "      <td>0.002170</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1001</td>\n",
       "      <td>1997</td>\n",
       "      <td>0.001853</td>\n",
       "      <td>0.001233</td>\n",
       "      <td>0.002386</td>\n",
       "      <td>0.000840</td>\n",
       "      <td>1.112023</td>\n",
       "      <td>41.174500</td>\n",
       "      <td>0.035283</td>\n",
       "      <td>0.001164</td>\n",
       "      <td>...</td>\n",
       "      <td>1.245044</td>\n",
       "      <td>1.448812</td>\n",
       "      <td>0.693670</td>\n",
       "      <td>0.001287</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1001</td>\n",
       "      <td>2002</td>\n",
       "      <td>0.000602</td>\n",
       "      <td>0.001494</td>\n",
       "      <td>0.002450</td>\n",
       "      <td>0.001504</td>\n",
       "      <td>1.746593</td>\n",
       "      <td>50.713380</td>\n",
       "      <td>0.054131</td>\n",
       "      <td>0.001073</td>\n",
       "      <td>...</td>\n",
       "      <td>0.905151</td>\n",
       "      <td>1.007785</td>\n",
       "      <td>1.046863</td>\n",
       "      <td>0.001853</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1001</td>\n",
       "      <td>2007</td>\n",
       "      <td>0.000898</td>\n",
       "      <td>0.000702</td>\n",
       "      <td>0.001817</td>\n",
       "      <td>0.000611</td>\n",
       "      <td>1.081845</td>\n",
       "      <td>45.171143</td>\n",
       "      <td>0.036063</td>\n",
       "      <td>0.000758</td>\n",
       "      <td>...</td>\n",
       "      <td>0.801518</td>\n",
       "      <td>1.088810</td>\n",
       "      <td>1.051707</td>\n",
       "      <td>0.000602</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1002</td>\n",
       "      <td>1992</td>\n",
       "      <td>0.002931</td>\n",
       "      <td>0.001549</td>\n",
       "      <td>0.002111</td>\n",
       "      <td>0.000959</td>\n",
       "      <td>1.176876</td>\n",
       "      <td>28.052156</td>\n",
       "      <td>0.020148</td>\n",
       "      <td>0.001266</td>\n",
       "      <td>...</td>\n",
       "      <td>1.020560</td>\n",
       "      <td>1.036390</td>\n",
       "      <td>1.251689</td>\n",
       "      <td>0.003141</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 68 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   zipcode  start_year  avg_eqi_year_5-10  year_1_EQI_MSA  year_1_EQI_state  \\\n",
       "0     1001        1992           0.001287        0.001549          0.002111   \n",
       "1     1001        1997           0.001853        0.001233          0.002386   \n",
       "2     1001        2002           0.000602        0.001494          0.002450   \n",
       "3     1001        2007           0.000898        0.000702          0.001817   \n",
       "4     1002        1992           0.002931        0.001549          0.002111   \n",
       "\n",
       "   year_1_EQI_zip  year_1_RECPI_MSA  year_1_RECPI_state  year_1_RECPI_zip  \\\n",
       "0        0.002216          1.176876           28.052156          0.048744   \n",
       "1        0.000840          1.112023           41.174500          0.035283   \n",
       "2        0.001504          1.746593           50.713380          0.054131   \n",
       "3        0.000611          1.081845           45.171143          0.036063   \n",
       "4        0.000959          1.176876           28.052156          0.020148   \n",
       "\n",
       "   year_2_EQI_MSA  ...  recpi_state_change_2  recpi_state_change_3  \\\n",
       "0        0.001266  ...              1.020560              1.036390   \n",
       "1        0.001164  ...              1.245044              1.448812   \n",
       "2        0.001073  ...              0.905151              1.007785   \n",
       "3        0.000758  ...              0.801518              1.088810   \n",
       "4        0.001266  ...              1.020560              1.036390   \n",
       "\n",
       "   recpi_state_change_4  avg_eqi_year_1-5  dataset_cluster  zip_cluster  \\\n",
       "0              1.251689          0.002170                3            0   \n",
       "1              0.693670          0.001287                3            0   \n",
       "2              1.046863          0.001853                3            0   \n",
       "3              1.051707          0.000602                3            0   \n",
       "4              1.251689          0.003141                3            1   \n",
       "\n",
       "   msa_cluster  state_cluster  eqi_cluster  recpi_cluster  \n",
       "0            0              1            0              0  \n",
       "1            0              1            0              0  \n",
       "2            0              1            0              0  \n",
       "3            0              1            0              0  \n",
       "4            0              1            0              0  \n",
       "\n",
       "[5 rows x 68 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filename = '../../data/processed/feature-eng-clustered.csv'\n",
    "df = pd.read_csv(filename)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df['zipcode'].unique()\n",
    "y = df['zipcode'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop('avg_eqi_year_5-10', axis=1)\n",
    "y = df[['zipcode','start_year','avg_eqi_year_5-10']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.DataFrame(X_train)\n",
    "X_train.columns = ['zipcode']\n",
    "\n",
    "X_test = pd.DataFrame(X_test)\n",
    "X_test.columns = ['zipcode']\n",
    "\n",
    "y_train = pd.DataFrame(y_train)\n",
    "y_train.columns = ['zipcode']\n",
    "\n",
    "y_test = pd.DataFrame(y_test)\n",
    "y_test.columns = ['zipcode']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.merge(X, on='zipcode').sort_values(['zipcode','start_year'], ignore_index=True)\n",
    "X_test = X_test.merge(X, on='zipcode').sort_values(['zipcode','start_year'], ignore_index=True)\n",
    "y_train = y_train.merge(y, on='zipcode').sort_values(['zipcode','start_year'], ignore_index=True)\n",
    "y_test = y_test.merge(y, on='zipcode').sort_values(['zipcode','start_year'], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = X_test.drop(['zipcode','start_year'], axis=1)\n",
    "X_train = X_train.drop(['zipcode','start_year'], axis=1)\n",
    "y_test = y_test[['avg_eqi_year_5-10']].to_numpy().ravel()\n",
    "y_train = y_train[['avg_eqi_year_5-10']].to_numpy().ravel()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer, make_column_selector\n",
    "from sklearn.metrics import r2_score, mean_gamma_deviance\n",
    "from skopt import BayesSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ColumnTransformer(transformers=[('scale', StandardScaler(),\n",
       "                                 <sklearn.compose._column_transformer.make_column_selector object at 0x0000021811C64970>),\n",
       "                                ('dataset_cluster', OneHotEncoder(dtype='int'),\n",
       "                                 ['dataset_cluster']),\n",
       "                                ('zip_cluster', OneHotEncoder(dtype='int'),\n",
       "                                 ['zip_cluster']),\n",
       "                                ('msa_cluster', OneHotEncoder(dtype='int'),\n",
       "                                 ['msa_cluster']),\n",
       "                                ('state_cluster', OneHotEncoder(dtype='int'),\n",
       "                                 ['state_cluster']),\n",
       "                                ('eqi_cluster', OneHotEncoder(dtype='int'),\n",
       "                                 ['eqi_cluster']),\n",
       "                                ('recpi_cluster', OneHotEncoder(dtype='int'),\n",
       "                                 ['recpi_cluster'])])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "column_trans = ColumnTransformer([\n",
    "    ('scale', StandardScaler(), make_column_selector(dtype_include=np.float64)),\n",
    "    ('dataset_cluster', OneHotEncoder(dtype='int'), ['dataset_cluster']),\n",
    "    ('zip_cluster', OneHotEncoder(dtype='int'), ['zip_cluster']),\n",
    "    ('msa_cluster', OneHotEncoder(dtype='int'), ['msa_cluster']),\n",
    "    ('state_cluster', OneHotEncoder(dtype='int'), ['state_cluster']),\n",
    "    ('eqi_cluster', OneHotEncoder(dtype='int'), ['eqi_cluster']),\n",
    "    ('recpi_cluster', OneHotEncoder(dtype='int'), ['recpi_cluster'])\n",
    "    ], remainder='drop')\n",
    "column_trans.fit(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNN Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {\n",
    "    'knn__n_neighbors': (1,31),\n",
    "    'knn__weights': ['uniform', 'distance'],\n",
    "    'knn__metric': ['euclidean', 'manhattan']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = Pipeline([('transformer', column_trans), ('knn', KNeighborsRegressor())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = BayesSearchCV(pipe, parameters, n_iter=40, n_points=3, cv=3, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1.total_iterations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def on_step(optim_result):\n",
    "    score = model1.best_score_\n",
    "    print(\"best score: %s\" % score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best score: 0.34043062362836385\n",
      "best score: 0.34194108639576154\n",
      "best score: 0.3433660598575949\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\thoma\\anaconda3\\envs\\capstone-02\\lib\\site-packages\\skopt\\optimizer\\optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
      "  warnings.warn(\"The objective has been evaluated \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best score: 0.3433660598575949\n",
      "best score: 0.3433660598575949\n",
      "best score: 0.3433660598575949\n",
      "best score: 0.3433660598575949\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BayesSearchCV(cv=3,\n",
       "              estimator=Pipeline(steps=[('transformer',\n",
       "                                         ColumnTransformer(transformers=[('scale',\n",
       "                                                                          StandardScaler(),\n",
       "                                                                          <sklearn.compose._column_transformer.make_column_selector object at 0x000001F582CB9BE0>),\n",
       "                                                                         ('dataset_cluster',\n",
       "                                                                          OneHotEncoder(dtype='int'),\n",
       "                                                                          ['dataset_cluster']),\n",
       "                                                                         ('zip_cluster',\n",
       "                                                                          OneHotEncoder(dtype='int'),\n",
       "                                                                          ['zip_cluster']),\n",
       "                                                                         ('msa_cluster',\n",
       "                                                                          OneHo...\n",
       "                                                                          OneHotEncoder(dtype='int'),\n",
       "                                                                          ['state_cluster']),\n",
       "                                                                         ('eqi_cluster',\n",
       "                                                                          OneHotEncoder(dtype='int'),\n",
       "                                                                          ['eqi_cluster']),\n",
       "                                                                         ('recpi_cluster',\n",
       "                                                                          OneHotEncoder(dtype='int'),\n",
       "                                                                          ['recpi_cluster'])])),\n",
       "                                        ('knn', KNeighborsRegressor())]),\n",
       "              n_iter=20, n_jobs=-1, n_points=3,\n",
       "              search_spaces={'knn__metric': ['euclidean', 'manhattan'],\n",
       "                             'knn__n_neighbors': (1, 31),\n",
       "                             'knn__weights': ['uniform', 'distance']})"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1.fit(X_train, y_train, callback=on_step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val. score: 0.3433660598575949\n",
      "test score: 0.5284269787793014\n",
      "best params: OrderedDict([('knn__metric', 'manhattan'), ('knn__n_neighbors', 11), ('knn__weights', 'distance')])\n"
     ]
    }
   ],
   "source": [
    "print(\"val. score: %s\" % model1.best_score_)\n",
    "print(\"test score: %s\" % model1.score(X_test, y_test))\n",
    "print(\"best params: %s\" % str(model1.best_params_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of trees in random forest\n",
    "n_estimators = (200, 2000)\n",
    "# Number of features to consider at every split\n",
    "max_features = ['auto', 'sqrt']\n",
    "# Maximum number of levels in tree\n",
    "max_depth = (10,110)\n",
    "# Minimum number of samples required to split a node\n",
    "min_samples_split = [2, 5, 10]\n",
    "# Minimum number of samples required at each leaf node\n",
    "min_samples_leaf = [1, 2, 4]\n",
    "# Method of selecting samples for training each tree\n",
    "bootstrap = [True, False]\n",
    "# Create the random grid\n",
    "parameters = {'rf__n_estimators': n_estimators,\n",
    "               'rf__max_features': max_features,\n",
    "               'rf__max_depth': max_depth,\n",
    "               'rf__min_samples_split': min_samples_split,\n",
    "               'rf__min_samples_leaf': min_samples_leaf,\n",
    "               'rf__bootstrap': bootstrap}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = Pipeline([('transformer', column_trans), ('rf', RandomForestRegressor(n_jobs=-1))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = BayesSearchCV(pipe, parameters, n_iter=10, n_points=3, cv=3, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.total_iterations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def on_step(optim_result):\n",
    "    score = model2.best_score_\n",
    "    print(\"best score: %s\" % score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best score: 0.38811298834883523\n",
      "best score: 0.3894891126961437\n",
      "best score: 0.3894891126961437\n",
      "best score: 0.3894891126961437\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BayesSearchCV(cv=3,\n",
       "              estimator=Pipeline(steps=[('transformer',\n",
       "                                         ColumnTransformer(transformers=[('scale',\n",
       "                                                                          StandardScaler(),\n",
       "                                                                          <sklearn.compose._column_transformer.make_column_selector object at 0x0000021811C64970>),\n",
       "                                                                         ('dataset_cluster',\n",
       "                                                                          OneHotEncoder(dtype='int'),\n",
       "                                                                          ['dataset_cluster']),\n",
       "                                                                         ('zip_cluster',\n",
       "                                                                          OneHotEncoder(dtype='int'),\n",
       "                                                                          ['zip_cluster']),\n",
       "                                                                         ('msa_cluster',\n",
       "                                                                          OneHo...\n",
       "                                                                          ['eqi_cluster']),\n",
       "                                                                         ('recpi_cluster',\n",
       "                                                                          OneHotEncoder(dtype='int'),\n",
       "                                                                          ['recpi_cluster'])])),\n",
       "                                        ('rf',\n",
       "                                         RandomForestRegressor(n_jobs=-1))]),\n",
       "              n_iter=10, n_jobs=-1, n_points=3,\n",
       "              search_spaces={'rf__bootstrap': [True, False],\n",
       "                             'rf__max_depth': (10, 110),\n",
       "                             'rf__max_features': ['auto', 'sqrt'],\n",
       "                             'rf__min_samples_leaf': [1, 2, 4],\n",
       "                             'rf__min_samples_split': [2, 5, 10],\n",
       "                             'rf__n_estimators': (200, 2000)})"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.fit(X_train, y_train, callback=on_step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val. score: 0.3894891126961437\n",
      "test score: 0.6048412796479616\n",
      "best params: OrderedDict([('rf__bootstrap', False), ('rf__max_depth', 72), ('rf__max_features', 'sqrt'), ('rf__min_samples_leaf', 4), ('rf__min_samples_split', 2), ('rf__n_estimators', 315)])\n"
     ]
    }
   ],
   "source": [
    "print(\"val. score: %s\" % model2.best_score_)\n",
    "print(\"test score: %s\" % model2.score(X_test, y_test))\n",
    "print(\"best params: %s\" % str(model2.best_params_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {\n",
    "    \"gbr__learning_rate\": [0.01, 0.025, 0.05, 0.075, 0.1, 0.15, 0.2],\n",
    "    \"gbr__min_samples_split\": (0.1, 0.5),\n",
    "    \"gbr__min_samples_leaf\": (0.1, 0.5),\n",
    "    \"gbr__max_depth\":[3,5,8],\n",
    "    \"gbr__max_features\":[\"log2\",\"sqrt\"],\n",
    "    \"gbr__criterion\": [\"friedman_mse\",  \"mae\"],\n",
    "    \"gbr__subsample\":[0.5, 0.618, 0.8, 0.85, 0.9, 0.95, 1.0],\n",
    "    \"gbr__n_estimators\":[10]\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = Pipeline([('transformer', column_trans), ('gbr', GradientBoostingRegressor())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "model3 = BayesSearchCV(pipe, parameters, n_iter=10, n_points=3, cv=3, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "80"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model3.total_iterations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def on_step(optim_result):\n",
    "    score = model3.best_score_\n",
    "    print(\"best score: %s\" % score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best score: 0.009754694827970204\n",
      "best score: 0.046440730882059286\n",
      "best score: 0.1012259832335307\n",
      "best score: 0.1012259832335307\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BayesSearchCV(cv=3,\n",
       "              estimator=Pipeline(steps=[('transformer',\n",
       "                                         ColumnTransformer(transformers=[('scale',\n",
       "                                                                          StandardScaler(),\n",
       "                                                                          <sklearn.compose._column_transformer.make_column_selector object at 0x0000021811C64970>),\n",
       "                                                                         ('dataset_cluster',\n",
       "                                                                          OneHotEncoder(dtype='int'),\n",
       "                                                                          ['dataset_cluster']),\n",
       "                                                                         ('zip_cluster',\n",
       "                                                                          OneHotEncoder(dtype='int'),\n",
       "                                                                          ['zip_cluster']),\n",
       "                                                                         ('msa_cluster',\n",
       "                                                                          OneHo...\n",
       "              n_iter=10, n_jobs=-1, n_points=3,\n",
       "              search_spaces={'gbr__criterion': ['friedman_mse', 'mae'],\n",
       "                             'gbr__learning_rate': [0.01, 0.025, 0.05, 0.075,\n",
       "                                                    0.1, 0.15, 0.2],\n",
       "                             'gbr__max_depth': [3, 5, 8],\n",
       "                             'gbr__max_features': ['log2', 'sqrt'],\n",
       "                             'gbr__min_samples_leaf': (0.1, 0.5),\n",
       "                             'gbr__min_samples_split': (0.1, 0.5),\n",
       "                             'gbr__n_estimators': [10],\n",
       "                             'gbr__subsample': [0.5, 0.618, 0.8, 0.85, 0.9,\n",
       "                                                0.95, 1.0]})"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model3.fit(X_train, y_train, callback=on_step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val. score: 0.1012259832335307\n",
      "test score: 0.1263938831267737\n",
      "best params: OrderedDict([('gbr__criterion', 'friedman_mse'), ('gbr__learning_rate', 0.2), ('gbr__max_depth', 3), ('gbr__max_features', 'sqrt'), ('gbr__min_samples_leaf', 0.2608960555840142), ('gbr__min_samples_split', 0.17133048643520515), ('gbr__n_estimators', 10), ('gbr__subsample', 0.85)])\n"
     ]
    }
   ],
   "source": [
    "print(\"val. score: %s\" % model3.best_score_)\n",
    "print(\"test score: %s\" % model3.score(X_test, y_test))\n",
    "print(\"best params: %s\" % str(model3.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
